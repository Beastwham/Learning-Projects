{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ce1339",
      "metadata": {
        "id": "d5ce1339",
        "outputId": "87e4ba2f-0372-41f1-d18f-36c408583aa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
          ]
        }
      ],
      "source": [
        "# Importing libraries\n",
        "import nltk\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "# download the treebank corpus from nltk\n",
        "nltk.download('treebank')\n",
        " \n",
        "# download the universal tagset from nltk\n",
        "nltk.download('universal_tagset')\n",
        " \n",
        "# reading the Treebank tagged sentences\n",
        "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
        " \n",
        "# print the first two sentences along with tags\n",
        "print(nltk_data[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5139cc4d",
      "metadata": {
        "id": "5139cc4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d781c9-4a6e-4303-bc7e-b2b8cb931f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============\n",
            "('Pierre', 'NOUN')\n",
            "('Vinken', 'NOUN')\n",
            "(',', '.')\n",
            "('61', 'NUM')\n",
            "('years', 'NOUN')\n",
            "('old', 'ADJ')\n",
            "(',', '.')\n",
            "('will', 'VERB')\n",
            "('join', 'VERB')\n",
            "('the', 'DET')\n",
            "('board', 'NOUN')\n",
            "('as', 'ADP')\n",
            "('a', 'DET')\n",
            "('nonexecutive', 'ADJ')\n",
            "('director', 'NOUN')\n",
            "('Nov.', 'NOUN')\n",
            "('29', 'NUM')\n",
            "('.', '.')\n",
            "==============\n",
            "('Mr.', 'NOUN')\n",
            "('Vinken', 'NOUN')\n",
            "('is', 'VERB')\n",
            "('chairman', 'NOUN')\n",
            "('of', 'ADP')\n",
            "('Elsevier', 'NOUN')\n",
            "('N.V.', 'NOUN')\n",
            "(',', '.')\n",
            "('the', 'DET')\n",
            "('Dutch', 'NOUN')\n",
            "('publishing', 'VERB')\n",
            "('group', 'NOUN')\n",
            "('.', '.')\n"
          ]
        }
      ],
      "source": [
        "# print each word with its respective tag for first two sentences\n",
        "for sent in nltk_data[:2]:\n",
        "    print('==============')\n",
        "    for tuple in sent:\n",
        "        print(tuple,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da8b463b",
      "metadata": {
        "id": "da8b463b"
      },
      "outputs": [],
      "source": [
        "# split data into training and validation set in the ratio 80:20\n",
        "train_set, test_set = train_test_split(nltk_data, train_size = 0.80, test_size = 0.20, random_state = 101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433a57bf",
      "metadata": {
        "id": "433a57bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78e8715-72b2-44bd-ceb6-8e757d5faecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80310\n",
            "20366\n"
          ]
        }
      ],
      "source": [
        "# create list of train and test tagged words\n",
        "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
        "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
        "print(len(train_tagged_words))\n",
        "print(len(test_tagged_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47a8c1e9",
      "metadata": {
        "id": "47a8c1e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4d53e3-af54-42f4-fb47-7ab0ec7d8c55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Drink', 'NOUN'),\n",
              " ('Carrier', 'NOUN'),\n",
              " ('Competes', 'VERB'),\n",
              " ('With', 'ADP'),\n",
              " ('Cartons', 'NOUN')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# check some of the tagged words.\n",
        "train_tagged_words[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d813ad7c",
      "metadata": {
        "id": "d813ad7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3a8442-7621-447a-b611-d8162d553411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tags: 12\n",
            "{'.', 'DET', 'VERB', 'NOUN', 'ADV', 'NUM', 'CONJ', 'ADJ', 'ADP', 'X', 'PRON', 'PRT'}\n",
            "Number of words in vocabulary: 11052\n"
          ]
        }
      ],
      "source": [
        "# use set datatype to check how many unique tags are present in training data\n",
        "tags = {tag for word, tag in train_tagged_words}\n",
        "print('Number of tags:', len(tags))\n",
        "print(tags)\n",
        " \n",
        "# check total words in vocabulary\n",
        "vocab = {word for word, tag in train_tagged_words}\n",
        "print('Number of words in vocabulary:', len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating encoding dictionaries\n",
        "encode_hs = {}\n",
        "decode_hs = {}\n",
        "for idx, t in enumerate(tags):\n",
        "    encode_hs[t] = idx\n",
        "    decode_hs[idx] = t\n",
        "print(\"Encode: \\n\", encode_hs)\n",
        "print(\"Decode: \\n\", decode_hs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esw8wuf4Qnh_",
        "outputId": "6bf8f33c-86c1-4e44-8c5a-e97e374a762a"
      },
      "id": "esw8wuf4Qnh_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encode: \n",
            " {'.': 0, 'DET': 1, 'VERB': 2, 'NOUN': 3, 'ADV': 4, 'NUM': 5, 'CONJ': 6, 'ADJ': 7, 'ADP': 8, 'X': 9, 'PRON': 10, 'PRT': 11}\n",
            "Decode: \n",
            " {0: '.', 1: 'DET', 2: 'VERB', 3: 'NOUN', 4: 'ADV', 5: 'NUM', 6: 'CONJ', 7: 'ADJ', 8: 'ADP', 9: 'X', 10: 'PRON', 11: 'PRT'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding for Visible States\n",
        "encode_vs = {}\n",
        "for v,k in enumerate(vocab):\n",
        "    encode_vs[k] = v\n",
        "encode_vs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJT2uNCDQsMV",
        "outputId": "31b939e1-1a16-4b40-ea14-6184dcb992c2"
      },
      "id": "HJT2uNCDQsMV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negotiator': 0,\n",
              " 'belts': 1,\n",
              " 'galvanized': 2,\n",
              " 'certain': 3,\n",
              " 'Urban': 4,\n",
              " 'ships': 5,\n",
              " 'Services': 6,\n",
              " 'intelligence': 7,\n",
              " 'responses': 8,\n",
              " 'short-term': 9,\n",
              " 'entrenched': 10,\n",
              " 'longest': 11,\n",
              " 'ABA': 12,\n",
              " 'Daniel': 13,\n",
              " 'influenced': 14,\n",
              " 'Moreover': 15,\n",
              " 'Ichiro': 16,\n",
              " 'Firms': 17,\n",
              " 'Neanderthals': 18,\n",
              " 'Literacy': 19,\n",
              " 'B': 20,\n",
              " '*T*-53': 21,\n",
              " 'apparent': 22,\n",
              " '494.50': 23,\n",
              " 'Only': 24,\n",
              " 'begun': 25,\n",
              " 'town': 26,\n",
              " '*ICH*-1': 27,\n",
              " \"'re\": 28,\n",
              " 'speed': 29,\n",
              " 'Craftsmen': 30,\n",
              " 'purchasers': 31,\n",
              " 'flagrant': 32,\n",
              " 'career': 33,\n",
              " 'speculative': 34,\n",
              " 'pursued': 35,\n",
              " 'acquisitions': 36,\n",
              " 'Soldado': 37,\n",
              " 'Louisiana-Pacific': 38,\n",
              " 'unveiled': 39,\n",
              " 'Illinois': 40,\n",
              " 'single-handed': 41,\n",
              " 'feels': 42,\n",
              " 'certificates': 43,\n",
              " 'LANDOR': 44,\n",
              " 'failing': 45,\n",
              " 'refused': 46,\n",
              " 'linked': 47,\n",
              " '7\\\\/16': 48,\n",
              " 'Nippon': 49,\n",
              " 'teaching': 50,\n",
              " 'Cluff': 51,\n",
              " 'stimulated': 52,\n",
              " 'emergencies': 53,\n",
              " 'alienated': 54,\n",
              " 'articles': 55,\n",
              " 'perpetual': 56,\n",
              " 'Ann': 57,\n",
              " '71': 58,\n",
              " 'possessions': 59,\n",
              " 'agree': 60,\n",
              " 'printed': 61,\n",
              " '566.54': 62,\n",
              " 'disapproval': 63,\n",
              " '730': 64,\n",
              " 'coordinator': 65,\n",
              " 'deaths': 66,\n",
              " 'hardly': 67,\n",
              " 'Tots': 68,\n",
              " '334.5': 69,\n",
              " 'Van': 70,\n",
              " 'marrow': 71,\n",
              " 'embroiled': 72,\n",
              " 'less': 73,\n",
              " 'likely': 74,\n",
              " 'plunging': 75,\n",
              " 'Communist': 76,\n",
              " 'low-cost': 77,\n",
              " '1940s': 78,\n",
              " 'Frank': 79,\n",
              " 'bankers': 80,\n",
              " 'Jovanovich': 81,\n",
              " 'vans': 82,\n",
              " '5.435': 83,\n",
              " 'fraction': 84,\n",
              " 'Texaco': 85,\n",
              " 'scholar': 86,\n",
              " 'detective-story': 87,\n",
              " 'beginning': 88,\n",
              " 'Ednie': 89,\n",
              " 'Coche-Dury': 90,\n",
              " 'SHAREDATA': 91,\n",
              " 'attendance': 92,\n",
              " 'museums': 93,\n",
              " 'inner-city': 94,\n",
              " 'disaster-assistance': 95,\n",
              " 'urge': 96,\n",
              " 'Katzenstein': 97,\n",
              " 'do': 98,\n",
              " '1990-91': 99,\n",
              " 'of': 100,\n",
              " 'unveil': 101,\n",
              " 'named': 102,\n",
              " 'trading': 103,\n",
              " 'shipments': 104,\n",
              " 'Section': 105,\n",
              " 'regulators': 106,\n",
              " 'selling': 107,\n",
              " 'mines': 108,\n",
              " 'PHOTOGRAPH': 109,\n",
              " '35.2': 110,\n",
              " 'world-wide': 111,\n",
              " '*-56': 112,\n",
              " 'perfection': 113,\n",
              " 'bomb': 114,\n",
              " 'promises': 115,\n",
              " 'bribe': 116,\n",
              " 'floral': 117,\n",
              " 'took': 118,\n",
              " 'blood-cell': 119,\n",
              " 'giveaways': 120,\n",
              " 'five-year': 121,\n",
              " 'self-perpetuating': 122,\n",
              " '47': 123,\n",
              " 'forum': 124,\n",
              " '5.1': 125,\n",
              " 'lower': 126,\n",
              " 'resolution': 127,\n",
              " 'worthiness': 128,\n",
              " 'write-downs': 129,\n",
              " 'worries': 130,\n",
              " 'accused': 131,\n",
              " 'proposition': 132,\n",
              " 'neighbors': 133,\n",
              " 'prototype': 134,\n",
              " 'enjoy': 135,\n",
              " 'agreed-upon': 136,\n",
              " 'late': 137,\n",
              " 'ran': 138,\n",
              " 'RULING': 139,\n",
              " 'consider': 140,\n",
              " '*-146': 141,\n",
              " 'disagreed': 142,\n",
              " 'mathematics': 143,\n",
              " 'reeling': 144,\n",
              " 'Several': 145,\n",
              " 'run-down': 146,\n",
              " 'got': 147,\n",
              " '16.05': 148,\n",
              " '5.39': 149,\n",
              " 'start-up': 150,\n",
              " 'Citizens': 151,\n",
              " 'Sacramento': 152,\n",
              " 'guilders': 153,\n",
              " 'climbed': 154,\n",
              " 'unofficial': 155,\n",
              " '*T*-48': 156,\n",
              " 'Silicon': 157,\n",
              " 'whereby': 158,\n",
              " 'Erbamont': 159,\n",
              " 'robustly': 160,\n",
              " 'Ballantine\\\\/Del': 161,\n",
              " 'depending': 162,\n",
              " 'moons': 163,\n",
              " 'Negus': 164,\n",
              " 'proof': 165,\n",
              " 'methods': 166,\n",
              " 'mode': 167,\n",
              " 'overhead': 168,\n",
              " '1990': 169,\n",
              " 'sank': 170,\n",
              " '227': 171,\n",
              " '*ICH*-4': 172,\n",
              " 'wedded': 173,\n",
              " '*T*-63': 174,\n",
              " 'sort': 175,\n",
              " 'Bodner': 176,\n",
              " 'winding': 177,\n",
              " 'pledged': 178,\n",
              " 'financial-services': 179,\n",
              " 'emotions': 180,\n",
              " 'Monday': 181,\n",
              " 'circuit': 182,\n",
              " 'Fargo': 183,\n",
              " 'McGraw-Hill': 184,\n",
              " 'agenda': 185,\n",
              " 'encounter': 186,\n",
              " 'fleeting': 187,\n",
              " '*-23': 188,\n",
              " 'command': 189,\n",
              " 'During': 190,\n",
              " 'talking': 191,\n",
              " 'recovery': 192,\n",
              " 'upturn': 193,\n",
              " 'fend': 194,\n",
              " '5.2180': 195,\n",
              " 'reforms': 196,\n",
              " 'process': 197,\n",
              " 'colony': 198,\n",
              " 'Send': 199,\n",
              " 'new-car': 200,\n",
              " 'providing': 201,\n",
              " 'rose': 202,\n",
              " 'disapprove': 203,\n",
              " 'Sangyo': 204,\n",
              " 'longevity': 205,\n",
              " 'electronics': 206,\n",
              " 'Growth': 207,\n",
              " 'refuge': 208,\n",
              " 'answers': 209,\n",
              " 'hidden': 210,\n",
              " 'attributes': 211,\n",
              " 'Minera': 212,\n",
              " 'period': 213,\n",
              " '*T*-112': 214,\n",
              " 'sufficiently': 215,\n",
              " 'gold': 216,\n",
              " 'Express': 217,\n",
              " 'assistance': 218,\n",
              " 'consomme': 219,\n",
              " 'Different': 220,\n",
              " 'Grandsire': 221,\n",
              " 'semiconductor': 222,\n",
              " 'Sen.': 223,\n",
              " 'bag': 224,\n",
              " 'wild': 225,\n",
              " 'drag-down': 226,\n",
              " 'technologies': 227,\n",
              " 'Angier': 228,\n",
              " 'Bugs': 229,\n",
              " '0.54': 230,\n",
              " 'computerized': 231,\n",
              " 'more-efficient': 232,\n",
              " 'Bradley': 233,\n",
              " '41.60': 234,\n",
              " 'become': 235,\n",
              " 'compensation': 236,\n",
              " 'firmly': 237,\n",
              " 'disapproved': 238,\n",
              " 'Great': 239,\n",
              " 'dumped': 240,\n",
              " '17.95': 241,\n",
              " 'ASLACTON': 242,\n",
              " 'booklet': 243,\n",
              " 'Income': 244,\n",
              " 'HUD': 245,\n",
              " 'Maine': 246,\n",
              " 'extremely': 247,\n",
              " 'exits': 248,\n",
              " 'ones': 249,\n",
              " 'impressed': 250,\n",
              " '1.76': 251,\n",
              " 'bidding': 252,\n",
              " 'surprised': 253,\n",
              " '6\\\\/2': 254,\n",
              " '*-50': 255,\n",
              " 'milk': 256,\n",
              " 'Aerospace': 257,\n",
              " 'characterizing': 258,\n",
              " 'rare': 259,\n",
              " 'sweat': 260,\n",
              " 'her': 261,\n",
              " 'above': 262,\n",
              " 'lagging': 263,\n",
              " 'nothing': 264,\n",
              " 'assert': 265,\n",
              " 'stake': 266,\n",
              " 'abortionist': 267,\n",
              " 'reference': 268,\n",
              " 'intraocular': 269,\n",
              " 'Louisville': 270,\n",
              " 'allowed': 271,\n",
              " 'Inc.': 272,\n",
              " 'Upham': 273,\n",
              " 'list': 274,\n",
              " 'INS': 275,\n",
              " 'obligated': 276,\n",
              " 'guards': 277,\n",
              " 'Indiana': 278,\n",
              " 'August': 279,\n",
              " 'sounded': 280,\n",
              " 'acquisition-minded': 281,\n",
              " 'tort': 282,\n",
              " 'joined': 283,\n",
              " 'casino': 284,\n",
              " 'release': 285,\n",
              " 'murder': 286,\n",
              " '13': 287,\n",
              " 'intent': 288,\n",
              " 'indirect': 289,\n",
              " 'chatter': 290,\n",
              " 'Bellows': 291,\n",
              " 'newsroom': 292,\n",
              " 'threat': 293,\n",
              " 'improves': 294,\n",
              " 'complete': 295,\n",
              " 'Stadium': 296,\n",
              " 'judiciary': 297,\n",
              " 'Dorothy': 298,\n",
              " '*-24': 299,\n",
              " 'decay': 300,\n",
              " 'harmed': 301,\n",
              " 'nurtured': 302,\n",
              " 'votes': 303,\n",
              " 'clouds': 304,\n",
              " 'trade': 305,\n",
              " 'Signs': 306,\n",
              " 'ongoing': 307,\n",
              " 'fatalities': 308,\n",
              " 'separate': 309,\n",
              " 'Adolph': 310,\n",
              " '*T*-25': 311,\n",
              " 'Stockholders': 312,\n",
              " 'corrupt': 313,\n",
              " 'intertitles': 314,\n",
              " 'chief': 315,\n",
              " 'needing': 316,\n",
              " 'Correll': 317,\n",
              " 'restrictions': 318,\n",
              " 'contracted': 319,\n",
              " 'recognition': 320,\n",
              " 'Earlier': 321,\n",
              " '1970s': 322,\n",
              " 'First': 323,\n",
              " 'Average': 324,\n",
              " 'measurement': 325,\n",
              " 'Invariably': 326,\n",
              " 'idiomatic': 327,\n",
              " 'Diamond': 328,\n",
              " 'once': 329,\n",
              " 'consists': 330,\n",
              " 'presumably': 331,\n",
              " 'structure': 332,\n",
              " 'if': 333,\n",
              " '*-161': 334,\n",
              " 'plans': 335,\n",
              " 'about': 336,\n",
              " 'resonate': 337,\n",
              " 'ever': 338,\n",
              " 'covering': 339,\n",
              " '2000': 340,\n",
              " 'Reed': 341,\n",
              " 'targeted': 342,\n",
              " 'Bordeaux': 343,\n",
              " 'municipal': 344,\n",
              " 'Coast': 345,\n",
              " '14.00': 346,\n",
              " 'train': 347,\n",
              " 'slogan': 348,\n",
              " 'possess': 349,\n",
              " 'Professors': 350,\n",
              " 'co-chairman': 351,\n",
              " 'personal': 352,\n",
              " 'kill': 353,\n",
              " 'understatement': 354,\n",
              " 'York-based': 355,\n",
              " 'apartment': 356,\n",
              " 'Laura': 357,\n",
              " 'Mahoney': 358,\n",
              " 'pirates': 359,\n",
              " '12-member': 360,\n",
              " 'Fulton': 361,\n",
              " 'Barrett': 362,\n",
              " '...': 363,\n",
              " '27.4': 364,\n",
              " 'tall': 365,\n",
              " 'year-ago': 366,\n",
              " 'facing': 367,\n",
              " 'stuff': 368,\n",
              " 'certified': 369,\n",
              " 'lose': 370,\n",
              " 'really': 371,\n",
              " 'implementation': 372,\n",
              " '*-103': 373,\n",
              " 'Vinken': 374,\n",
              " 'government-funded': 375,\n",
              " 'Blue': 376,\n",
              " 'ambitions': 377,\n",
              " 'awareness': 378,\n",
              " 'direction': 379,\n",
              " 'stockbrokers': 380,\n",
              " 'thwart': 381,\n",
              " 'underline': 382,\n",
              " 'similar': 383,\n",
              " 'Shrum': 384,\n",
              " 'convenient': 385,\n",
              " 'wealth': 386,\n",
              " 'redistribute': 387,\n",
              " 'rally': 388,\n",
              " 'a': 389,\n",
              " 'cool': 390,\n",
              " 'unattractive': 391,\n",
              " '*T*-238': 392,\n",
              " 'modestly': 393,\n",
              " 'progressive': 394,\n",
              " 'Nylev': 395,\n",
              " 'tests': 396,\n",
              " 'monitor': 397,\n",
              " 'standard': 398,\n",
              " 'fluent': 399,\n",
              " 'Bradford': 400,\n",
              " '*T*-216': 401,\n",
              " 'Economists': 402,\n",
              " 'Steel': 403,\n",
              " 'contingent': 404,\n",
              " 'explanatory': 405,\n",
              " 'enclosed': 406,\n",
              " 'global': 407,\n",
              " 'creation': 408,\n",
              " '*-160': 409,\n",
              " 'waters': 410,\n",
              " 'resistant': 411,\n",
              " 'cover': 412,\n",
              " 'profitability': 413,\n",
              " 'scattered': 414,\n",
              " 'de': 415,\n",
              " '1,460': 416,\n",
              " 'DDB': 417,\n",
              " 'Judge': 418,\n",
              " 'not': 419,\n",
              " 'Canada': 420,\n",
              " 'chefs': 421,\n",
              " 'communications': 422,\n",
              " 'quipped': 423,\n",
              " 'revelations': 424,\n",
              " 'author': 425,\n",
              " 'Social': 426,\n",
              " 'fallen': 427,\n",
              " 'Cerf': 428,\n",
              " 'contests': 429,\n",
              " 'oil': 430,\n",
              " 'steelmakers': 431,\n",
              " 'solutions': 432,\n",
              " 'Goldinger': 433,\n",
              " 'problem': 434,\n",
              " 'Mannix': 435,\n",
              " 'shareholders': 436,\n",
              " 'Asked': 437,\n",
              " 'identical': 438,\n",
              " 'Mulford': 439,\n",
              " 'NESB': 440,\n",
              " 'nutty': 441,\n",
              " 'craft': 442,\n",
              " 'interesting': 443,\n",
              " '*-6': 444,\n",
              " 'made': 445,\n",
              " 'Pepperdine': 446,\n",
              " 'Alurralde': 447,\n",
              " 'Right': 448,\n",
              " 'stressing': 449,\n",
              " 'reportedly': 450,\n",
              " 'belt': 451,\n",
              " '3.42': 452,\n",
              " 'Thursday': 453,\n",
              " 'Martin': 454,\n",
              " '1614': 455,\n",
              " '*T*-208': 456,\n",
              " 'what': 457,\n",
              " 'surveyed': 458,\n",
              " 'reliance': 459,\n",
              " 'procedural': 460,\n",
              " 'slew': 461,\n",
              " 'triple-A': 462,\n",
              " '127.03': 463,\n",
              " 'Spain': 464,\n",
              " 'DNA': 465,\n",
              " '753': 466,\n",
              " 'seen': 467,\n",
              " 'Si': 468,\n",
              " '*T*-1': 469,\n",
              " 'protects': 470,\n",
              " 'wish': 471,\n",
              " 'House-Senate': 472,\n",
              " 'Garrison': 473,\n",
              " 'Antonio': 474,\n",
              " 'reservations': 475,\n",
              " 'dessert': 476,\n",
              " 'Henderson': 477,\n",
              " 'cardboard': 478,\n",
              " 'humans': 479,\n",
              " 'discarded': 480,\n",
              " 'restructure': 481,\n",
              " 'Army': 482,\n",
              " 'DSM': 483,\n",
              " 'fresh': 484,\n",
              " 'cushioned': 485,\n",
              " '68': 486,\n",
              " 'union': 487,\n",
              " 'Random': 488,\n",
              " 'food': 489,\n",
              " 'ringing': 490,\n",
              " '*?*': 491,\n",
              " '30,841': 492,\n",
              " 'Hotel': 493,\n",
              " 'thanks': 494,\n",
              " 'permission': 495,\n",
              " 'Ethel': 496,\n",
              " 'Mexican': 497,\n",
              " 'magicians': 498,\n",
              " 'goal': 499,\n",
              " 'April': 500,\n",
              " '6.4': 501,\n",
              " 'high-flying': 502,\n",
              " 'drinking': 503,\n",
              " 'widgets': 504,\n",
              " 'contain': 505,\n",
              " 'battery': 506,\n",
              " 'wins': 507,\n",
              " 'status': 508,\n",
              " 'trends': 509,\n",
              " 'plot': 510,\n",
              " 'gaining': 511,\n",
              " 'Critics': 512,\n",
              " 'doctor': 513,\n",
              " '1991': 514,\n",
              " 'Policy': 515,\n",
              " 'Hara': 516,\n",
              " 'yttrium-containing': 517,\n",
              " 'views': 518,\n",
              " 'gloomy': 519,\n",
              " 'books': 520,\n",
              " 'claims': 521,\n",
              " 'hour': 522,\n",
              " 'industrial': 523,\n",
              " '*-165': 524,\n",
              " '*T*-197': 525,\n",
              " 'chocolate': 526,\n",
              " 'processing': 527,\n",
              " 'Cigna': 528,\n",
              " '30,537': 529,\n",
              " 'Triton': 530,\n",
              " 'Educational': 531,\n",
              " 'beers': 532,\n",
              " 'purhasing': 533,\n",
              " 'introduced': 534,\n",
              " 'acquirer': 535,\n",
              " 'Petrus': 536,\n",
              " 'boutique': 537,\n",
              " 'handle': 538,\n",
              " 'implication': 539,\n",
              " 'Scotland': 540,\n",
              " 'threats': 541,\n",
              " 'may': 542,\n",
              " 'brokers': 543,\n",
              " '*T*-125': 544,\n",
              " 'prints': 545,\n",
              " 'reporting': 546,\n",
              " 'NetWare': 547,\n",
              " '6.40': 548,\n",
              " 'banquet': 549,\n",
              " 'assembly': 550,\n",
              " 'fraud': 551,\n",
              " 'Everything': 552,\n",
              " 'Factories': 553,\n",
              " 'sale': 554,\n",
              " 'warning': 555,\n",
              " '*-154': 556,\n",
              " 'Connecticut': 557,\n",
              " 'whimsical': 558,\n",
              " 'insurer': 559,\n",
              " 'Carlos': 560,\n",
              " 'non-U.S.': 561,\n",
              " 'asset-valuation': 562,\n",
              " 'Valhi': 563,\n",
              " 'import': 564,\n",
              " 'job': 565,\n",
              " 'location': 566,\n",
              " 'requiring': 567,\n",
              " 'Register': 568,\n",
              " 'Nevertheless': 569,\n",
              " 'preclude': 570,\n",
              " 'directors': 571,\n",
              " 'terrine': 572,\n",
              " 'weeks': 573,\n",
              " 'defensive': 574,\n",
              " 'lower-priced': 575,\n",
              " 'Fla.': 576,\n",
              " 'difference': 577,\n",
              " 'prohibiting': 578,\n",
              " 'Stores': 579,\n",
              " 'missed': 580,\n",
              " 'Embassy': 581,\n",
              " 'licensed': 582,\n",
              " 'undesirable': 583,\n",
              " 'Smelting': 584,\n",
              " 'Macmillan\\\\/McGraw-Hill': 585,\n",
              " 'Krenz': 586,\n",
              " 'Fulham': 587,\n",
              " 'takes': 588,\n",
              " 'staid': 589,\n",
              " 'Media': 590,\n",
              " 'investors': 591,\n",
              " 'namely': 592,\n",
              " 'meaning': 593,\n",
              " 'crane-safety': 594,\n",
              " 'fill': 595,\n",
              " 'mollified': 596,\n",
              " 'bout': 597,\n",
              " 'Estimated': 598,\n",
              " 'exceedingly': 599,\n",
              " 'plants': 600,\n",
              " 'Las': 601,\n",
              " 'suit': 602,\n",
              " 'Nationwide': 603,\n",
              " 'ability': 604,\n",
              " 'owns': 605,\n",
              " 'Trinity': 606,\n",
              " 'Chrysler': 607,\n",
              " 'distributed': 608,\n",
              " 'structurally': 609,\n",
              " 'players': 610,\n",
              " 'billing': 611,\n",
              " 'short': 612,\n",
              " 'standards': 613,\n",
              " 'expect': 614,\n",
              " 'sold': 615,\n",
              " 'researchers': 616,\n",
              " 'acquisition': 617,\n",
              " 'slide': 618,\n",
              " 'Farm': 619,\n",
              " 'low': 620,\n",
              " 'marks': 621,\n",
              " 'Wakayama': 622,\n",
              " 'Conference': 623,\n",
              " 'beneficiaries': 624,\n",
              " 'Gates': 625,\n",
              " 'nonprofit': 626,\n",
              " '645,000': 627,\n",
              " 'Pan': 628,\n",
              " 'Herrington': 629,\n",
              " 'standing': 630,\n",
              " 'chalk': 631,\n",
              " 'Stevens': 632,\n",
              " 'Family': 633,\n",
              " 'first-rate': 634,\n",
              " 'concentrating': 635,\n",
              " 'fainting': 636,\n",
              " 'forces': 637,\n",
              " 'born': 638,\n",
              " 'cash-and-stock': 639,\n",
              " 'users': 640,\n",
              " 'Olympic': 641,\n",
              " 'pistols': 642,\n",
              " 'Malcolm': 643,\n",
              " 'unsecured': 644,\n",
              " 'beyond': 645,\n",
              " 'mining': 646,\n",
              " 'lift': 647,\n",
              " 'U.N.-supervised': 648,\n",
              " 'includes': 649,\n",
              " 'diplomats': 650,\n",
              " 'allegedly': 651,\n",
              " 'loyalty': 652,\n",
              " 'parent': 653,\n",
              " 'everything': 654,\n",
              " 'deficiencies': 655,\n",
              " '130.6': 656,\n",
              " 'week': 657,\n",
              " 'Ore.': 658,\n",
              " 'malignant': 659,\n",
              " 'industry-supported': 660,\n",
              " 'received': 661,\n",
              " 'surgery': 662,\n",
              " '257': 663,\n",
              " 'music': 664,\n",
              " 'chain': 665,\n",
              " 'undertaking': 666,\n",
              " 'Joni': 667,\n",
              " 'permits': 668,\n",
              " 'On': 669,\n",
              " 'Few': 670,\n",
              " 'carefree': 671,\n",
              " 'Administration': 672,\n",
              " 'posting': 673,\n",
              " 'likelihood': 674,\n",
              " 'FAX': 675,\n",
              " 'deadwood': 676,\n",
              " 'vacation': 677,\n",
              " 'Netherlands': 678,\n",
              " 'stressed': 679,\n",
              " 'Foods': 680,\n",
              " 'Skokie': 681,\n",
              " 'gentle': 682,\n",
              " 'falls': 683,\n",
              " '*T*-22': 684,\n",
              " 'picture': 685,\n",
              " 'three': 686,\n",
              " 'bombers': 687,\n",
              " 'retentive': 688,\n",
              " 'Brownstein': 689,\n",
              " 'demonstrations': 690,\n",
              " 'portions': 691,\n",
              " 'vowed': 692,\n",
              " 'lasting': 693,\n",
              " 'Skinner': 694,\n",
              " 'passage': 695,\n",
              " 'illegally': 696,\n",
              " 'loaded': 697,\n",
              " 'roofs': 698,\n",
              " 'crystals': 699,\n",
              " 'unlike': 700,\n",
              " 'one-yen': 701,\n",
              " 'Burgundy': 702,\n",
              " 'slab': 703,\n",
              " 'drive': 704,\n",
              " '28': 705,\n",
              " 'limbo': 706,\n",
              " 'fasteners': 707,\n",
              " 'permissible': 708,\n",
              " 'IMSAI': 709,\n",
              " '170,000': 710,\n",
              " 'objectives': 711,\n",
              " 'Pennsylvania': 712,\n",
              " 'decisions': 713,\n",
              " 'dollar': 714,\n",
              " 'Information': 715,\n",
              " 'overcome': 716,\n",
              " 'vague': 717,\n",
              " 'protocols': 718,\n",
              " 'school-board': 719,\n",
              " '*T*-241': 720,\n",
              " 'giant': 721,\n",
              " 'interstate': 722,\n",
              " 'proponents': 723,\n",
              " '32': 724,\n",
              " 'Nancy': 725,\n",
              " 'fourth': 726,\n",
              " 'hefty': 727,\n",
              " 'uncanny': 728,\n",
              " '2163.2': 729,\n",
              " 'Virgin': 730,\n",
              " 'tracks': 731,\n",
              " 'Yale': 732,\n",
              " 'accrued': 733,\n",
              " 'bids': 734,\n",
              " 'counterweight': 735,\n",
              " 'congressman': 736,\n",
              " 'counseling': 737,\n",
              " 'remainder': 738,\n",
              " '*T*-160': 739,\n",
              " 'tubular': 740,\n",
              " '16.09': 741,\n",
              " 'disclosure': 742,\n",
              " 'Saul': 743,\n",
              " 'violate': 744,\n",
              " 'root': 745,\n",
              " 'survey': 746,\n",
              " 'pregnant': 747,\n",
              " 'soliciting': 748,\n",
              " 'limit': 749,\n",
              " 'pushes': 750,\n",
              " 'pride': 751,\n",
              " 'Dallara': 752,\n",
              " '3.61': 753,\n",
              " 'Earns': 754,\n",
              " 'pulp': 755,\n",
              " '#': 756,\n",
              " '420': 757,\n",
              " 'Dean': 758,\n",
              " 'commitments': 759,\n",
              " 'Actually': 760,\n",
              " 'peddling': 761,\n",
              " 'Prater': 762,\n",
              " 'unique': 763,\n",
              " 'cap': 764,\n",
              " 'brokering': 765,\n",
              " 'Soup': 766,\n",
              " 'image': 767,\n",
              " '18.95': 768,\n",
              " 'cause': 769,\n",
              " 'bricks': 770,\n",
              " 'authority': 771,\n",
              " 'Stark': 772,\n",
              " 'degrees': 773,\n",
              " 'Kangyo': 774,\n",
              " 'Continental': 775,\n",
              " 'row': 776,\n",
              " 'Stoll': 777,\n",
              " '701': 778,\n",
              " 'Federation': 779,\n",
              " 'deputy': 780,\n",
              " 'Strait': 781,\n",
              " 'stresses': 782,\n",
              " 'evil': 783,\n",
              " 'reps': 784,\n",
              " 'Grgich': 785,\n",
              " 'dispute': 786,\n",
              " 'Beach': 787,\n",
              " 'Latin': 788,\n",
              " 'leave': 789,\n",
              " 'one-time': 790,\n",
              " 'Examiner': 791,\n",
              " 'cell': 792,\n",
              " 'Arabia': 793,\n",
              " 'Jefferson': 794,\n",
              " 'disproportionate': 795,\n",
              " 'Trans': 796,\n",
              " '191.9': 797,\n",
              " 'Maryland': 798,\n",
              " '3.75': 799,\n",
              " 'Cost-effective': 800,\n",
              " 'With': 801,\n",
              " 'fate': 802,\n",
              " 'livestock': 803,\n",
              " 'multitude': 804,\n",
              " 'Alexander': 805,\n",
              " 'Wayland': 806,\n",
              " 'class': 807,\n",
              " 'powerful': 808,\n",
              " 'deal': 809,\n",
              " 'rap': 810,\n",
              " 'triple-A-rated': 811,\n",
              " 'represent': 812,\n",
              " 'Net': 813,\n",
              " 'boomers': 814,\n",
              " 'monopolize': 815,\n",
              " 'comfort': 816,\n",
              " 'recombinant': 817,\n",
              " 'brain': 818,\n",
              " 'crop': 819,\n",
              " 'scoop': 820,\n",
              " 'discussed': 821,\n",
              " 'simple': 822,\n",
              " 'sell-off': 823,\n",
              " 'Georgetown': 824,\n",
              " 'weighing': 825,\n",
              " 'Preferences': 826,\n",
              " 'enter': 827,\n",
              " 'Heidelberg': 828,\n",
              " 'Walkman': 829,\n",
              " 'p.m.': 830,\n",
              " 'survive': 831,\n",
              " 'independence': 832,\n",
              " 'Stewart': 833,\n",
              " 'rumored': 834,\n",
              " 'Brigham': 835,\n",
              " 'Then': 836,\n",
              " 'withdrawal': 837,\n",
              " 'iota': 838,\n",
              " 'William': 839,\n",
              " 'worst-case': 840,\n",
              " 'executed': 841,\n",
              " 'amendments': 842,\n",
              " 'compelling': 843,\n",
              " 'impressive': 844,\n",
              " 'Peninsula': 845,\n",
              " 'Manila': 846,\n",
              " 'successful': 847,\n",
              " 'sagging': 848,\n",
              " 'credits': 849,\n",
              " 'emphasis': 850,\n",
              " 'club': 851,\n",
              " 'Cotran': 852,\n",
              " 'virtually': 853,\n",
              " '1.9': 854,\n",
              " 'Designated': 855,\n",
              " 'TRIMMING': 856,\n",
              " '341.20': 857,\n",
              " '*T*-146': 858,\n",
              " 'behemoth': 859,\n",
              " 'perpetuate': 860,\n",
              " '*T*-46': 861,\n",
              " 'Hammersmith': 862,\n",
              " 'pub': 863,\n",
              " 'meant': 864,\n",
              " 'needed': 865,\n",
              " 'Elsevier': 866,\n",
              " 'mortgaged': 867,\n",
              " 'feed': 868,\n",
              " '16': 869,\n",
              " 'freedoms': 870,\n",
              " 'Czech': 871,\n",
              " 'Bowery': 872,\n",
              " 'Komatsu': 873,\n",
              " 'cozy': 874,\n",
              " 'blank': 875,\n",
              " 'spring': 876,\n",
              " 'troubled': 877,\n",
              " 'impudent': 878,\n",
              " 'gelatin': 879,\n",
              " 'topped': 880,\n",
              " 'growths': 881,\n",
              " 'together': 882,\n",
              " 'COPPER': 883,\n",
              " '16.9': 884,\n",
              " 'six-bottle': 885,\n",
              " 'intriguing': 886,\n",
              " 'rentals': 887,\n",
              " 'tentatively': 888,\n",
              " 'Yasuda': 889,\n",
              " 'assured': 890,\n",
              " 'everyday': 891,\n",
              " 'N.C': 892,\n",
              " 'surprisingly': 893,\n",
              " 'Metallgesellschaft': 894,\n",
              " 'spokewoman': 895,\n",
              " 'Georgia-Pacific': 896,\n",
              " 'also': 897,\n",
              " 'Intermec': 898,\n",
              " 'chauffeur': 899,\n",
              " '1934': 900,\n",
              " '28.36': 901,\n",
              " 'committed': 902,\n",
              " 'MacDonald': 903,\n",
              " 'BANKERS': 904,\n",
              " 'wrestling': 905,\n",
              " '*T*-50': 906,\n",
              " 'discourage': 907,\n",
              " 'Make': 908,\n",
              " 'tad': 909,\n",
              " 'forgiven': 910,\n",
              " 'attempting': 911,\n",
              " '*T*-156': 912,\n",
              " 'expire': 913,\n",
              " 'Akerfeldt': 914,\n",
              " 'Wednesday': 915,\n",
              " 'hope': 916,\n",
              " 'racket': 917,\n",
              " 'Also': 918,\n",
              " 'acquires': 919,\n",
              " '150.00': 920,\n",
              " 'gift': 921,\n",
              " 'Chairman': 922,\n",
              " 'telecommunications': 923,\n",
              " 'observers': 924,\n",
              " 'How': 925,\n",
              " 'publish': 926,\n",
              " 'pressure': 927,\n",
              " 'instance': 928,\n",
              " 'Issues': 929,\n",
              " 'houses': 930,\n",
              " 'lauded': 931,\n",
              " 'Leo': 932,\n",
              " 'treating': 933,\n",
              " 'wrists': 934,\n",
              " 'People': 935,\n",
              " 'unwilling': 936,\n",
              " 'Arnold': 937,\n",
              " 'facility': 938,\n",
              " 'agricultural': 939,\n",
              " 'flexibility': 940,\n",
              " 'flows': 941,\n",
              " 'Keith': 942,\n",
              " '*T*-189': 943,\n",
              " 'uncharted': 944,\n",
              " 'Cru': 945,\n",
              " 'compensate': 946,\n",
              " 'considerably': 947,\n",
              " 'composite': 948,\n",
              " 'immune': 949,\n",
              " 'combat': 950,\n",
              " 'community': 951,\n",
              " 'rather': 952,\n",
              " 'Hurricane': 953,\n",
              " 'Delwin': 954,\n",
              " 'proscribes': 955,\n",
              " 'preset': 956,\n",
              " 'Shores': 957,\n",
              " 'forecasts': 958,\n",
              " 'Baris': 959,\n",
              " 'Sauternes': 960,\n",
              " 'indicators': 961,\n",
              " 'Division': 962,\n",
              " 'ads': 963,\n",
              " 'camera': 964,\n",
              " 'technically': 965,\n",
              " 'Scientists': 966,\n",
              " 'escrow': 967,\n",
              " 'represents': 968,\n",
              " 'less-serious': 969,\n",
              " 'proven': 970,\n",
              " 'delivered': 971,\n",
              " '9': 972,\n",
              " 'Its': 973,\n",
              " 'citation': 974,\n",
              " '767': 975,\n",
              " 'flourish': 976,\n",
              " 'mill': 977,\n",
              " '*-157': 978,\n",
              " '877,663': 979,\n",
              " 'active': 980,\n",
              " 'memory': 981,\n",
              " 'cancers': 982,\n",
              " 'factor': 983,\n",
              " '777': 984,\n",
              " 'Lure': 985,\n",
              " 'Ringing': 986,\n",
              " 'writing': 987,\n",
              " 'counts': 988,\n",
              " 'disk': 989,\n",
              " 'using': 990,\n",
              " 'YMCA': 991,\n",
              " 'pre-cooked': 992,\n",
              " 'test-practice': 993,\n",
              " 'Artist': 994,\n",
              " 'ingenuity': 995,\n",
              " 'procurement': 996,\n",
              " 'Holland': 997,\n",
              " 'tendering': 998,\n",
              " 'Mortgage-Backed': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing pi\n",
        "#Going with first word of each sentence\n",
        "pi = np.zeros(len(encode_hs))\n",
        "for sentence in train_set:\n",
        "    word, t = sentence[0]\n",
        "    pi[encode_hs[t]]+=1\n",
        "print(pi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyE7f5rTenIV",
        "outputId": "83b29bb4-a424-4567-ddcd-c5c9f3cfe544"
      },
      "id": "VyE7f5rTenIV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[248. 724.  34. 903. 165.  26. 166. 132. 417.  66. 245.   5.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing A\n",
        "A = np.zeros((len(encode_hs), len(encode_hs)), dtype = np.float128)\n",
        "\n",
        "for sentence in train_set:\n",
        "    for i in range(1,len(sentence)):\n",
        "        #Taking the second element of the tuple\n",
        "        t = sentence[i][1]\n",
        "        prev_t = sentence[i-1][1]\n",
        "        A[encode_hs[prev_t], encode_hs[t]] += 1\n",
        "\n",
        "A = A/np.reshape(np.sum(A, axis=1), (-1,1))\n",
        "\n",
        "pd.DataFrame(A, index = encode_hs.keys(), columns = encode_hs.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "833NCOvUQ3Qk",
        "outputId": "fbdc74a6-84d1-489c-d101-ade370281602"
      },
      "id": "833NCOvUQ3Qk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             .       DET      VERB      NOUN       ADV       NUM      CONJ  \\\n",
              ".     0.099163  0.142788  0.129105  0.183677  0.052318  0.113168  0.063748   \n",
              "DET   0.017395  0.005894  0.040253  0.635998  0.012076  0.022858  0.000431   \n",
              "VERB  0.034807  0.133610  0.167956  0.110589  0.083886  0.022836  0.005433   \n",
              "NOUN  0.240153  0.012984  0.149224  0.262330  0.016905  0.009150  0.042436   \n",
              "ADV   0.139309  0.071013  0.339154  0.032208  0.081490  0.029880  0.006985   \n",
              "NUM   0.118971  0.003573  0.020722  0.351554  0.003573  0.184352  0.014291   \n",
              "CONJ  0.035126  0.123491  0.150384  0.349067  0.057080  0.040615  0.000549   \n",
              "ADJ   0.066019  0.005243  0.011456  0.696893  0.005243  0.021748  0.016893   \n",
              "ADP   0.038739  0.321053  0.008482  0.323585  0.014559  0.063299  0.000886   \n",
              "X     0.160900  0.056709  0.206459  0.061707  0.025759  0.003076  0.010381   \n",
              "PRON  0.041913  0.009567  0.484738  0.212756  0.036902  0.006834  0.005011   \n",
              "PRT   0.045010  0.101370  0.401174  0.250489  0.009393  0.056751  0.002348   \n",
              "\n",
              "           ADJ       ADP         X      PRON       PRT  \n",
              ".     0.048133  0.072601  0.027849  0.064070  0.003381  \n",
              "DET   0.206440  0.009919  0.045141  0.003306  0.000288  \n",
              "VERB  0.066390  0.092357  0.215930  0.035543  0.030663  \n",
              "NOUN  0.012548  0.176847  0.028843  0.004618  0.043961  \n",
              "ADV   0.130772  0.119519  0.022895  0.012029  0.014746  \n",
              "NUM   0.035370  0.037513  0.202572  0.001429  0.026081  \n",
              "CONJ  0.113611  0.055982  0.009330  0.060373  0.004391  \n",
              "ADJ   0.063301  0.080583  0.020971  0.000194  0.011456  \n",
              "ADP   0.107102  0.016964  0.034561  0.069502  0.001266  \n",
              "X     0.017686  0.142253  0.075740  0.054210  0.185121  \n",
              "PRON  0.070615  0.022323  0.088383  0.006834  0.014123  \n",
              "PRT   0.082975  0.019569  0.012133  0.017613  0.001174  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d849a75-5805-48f6-8ad9-ac217dd8fa52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>.</th>\n",
              "      <th>DET</th>\n",
              "      <th>VERB</th>\n",
              "      <th>NOUN</th>\n",
              "      <th>ADV</th>\n",
              "      <th>NUM</th>\n",
              "      <th>CONJ</th>\n",
              "      <th>ADJ</th>\n",
              "      <th>ADP</th>\n",
              "      <th>X</th>\n",
              "      <th>PRON</th>\n",
              "      <th>PRT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>0.099163</td>\n",
              "      <td>0.142788</td>\n",
              "      <td>0.129105</td>\n",
              "      <td>0.183677</td>\n",
              "      <td>0.052318</td>\n",
              "      <td>0.113168</td>\n",
              "      <td>0.063748</td>\n",
              "      <td>0.048133</td>\n",
              "      <td>0.072601</td>\n",
              "      <td>0.027849</td>\n",
              "      <td>0.064070</td>\n",
              "      <td>0.003381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DET</th>\n",
              "      <td>0.017395</td>\n",
              "      <td>0.005894</td>\n",
              "      <td>0.040253</td>\n",
              "      <td>0.635998</td>\n",
              "      <td>0.012076</td>\n",
              "      <td>0.022858</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>0.206440</td>\n",
              "      <td>0.009919</td>\n",
              "      <td>0.045141</td>\n",
              "      <td>0.003306</td>\n",
              "      <td>0.000288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VERB</th>\n",
              "      <td>0.034807</td>\n",
              "      <td>0.133610</td>\n",
              "      <td>0.167956</td>\n",
              "      <td>0.110589</td>\n",
              "      <td>0.083886</td>\n",
              "      <td>0.022836</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.066390</td>\n",
              "      <td>0.092357</td>\n",
              "      <td>0.215930</td>\n",
              "      <td>0.035543</td>\n",
              "      <td>0.030663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOUN</th>\n",
              "      <td>0.240153</td>\n",
              "      <td>0.012984</td>\n",
              "      <td>0.149224</td>\n",
              "      <td>0.262330</td>\n",
              "      <td>0.016905</td>\n",
              "      <td>0.009150</td>\n",
              "      <td>0.042436</td>\n",
              "      <td>0.012548</td>\n",
              "      <td>0.176847</td>\n",
              "      <td>0.028843</td>\n",
              "      <td>0.004618</td>\n",
              "      <td>0.043961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADV</th>\n",
              "      <td>0.139309</td>\n",
              "      <td>0.071013</td>\n",
              "      <td>0.339154</td>\n",
              "      <td>0.032208</td>\n",
              "      <td>0.081490</td>\n",
              "      <td>0.029880</td>\n",
              "      <td>0.006985</td>\n",
              "      <td>0.130772</td>\n",
              "      <td>0.119519</td>\n",
              "      <td>0.022895</td>\n",
              "      <td>0.012029</td>\n",
              "      <td>0.014746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NUM</th>\n",
              "      <td>0.118971</td>\n",
              "      <td>0.003573</td>\n",
              "      <td>0.020722</td>\n",
              "      <td>0.351554</td>\n",
              "      <td>0.003573</td>\n",
              "      <td>0.184352</td>\n",
              "      <td>0.014291</td>\n",
              "      <td>0.035370</td>\n",
              "      <td>0.037513</td>\n",
              "      <td>0.202572</td>\n",
              "      <td>0.001429</td>\n",
              "      <td>0.026081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONJ</th>\n",
              "      <td>0.035126</td>\n",
              "      <td>0.123491</td>\n",
              "      <td>0.150384</td>\n",
              "      <td>0.349067</td>\n",
              "      <td>0.057080</td>\n",
              "      <td>0.040615</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.113611</td>\n",
              "      <td>0.055982</td>\n",
              "      <td>0.009330</td>\n",
              "      <td>0.060373</td>\n",
              "      <td>0.004391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADJ</th>\n",
              "      <td>0.066019</td>\n",
              "      <td>0.005243</td>\n",
              "      <td>0.011456</td>\n",
              "      <td>0.696893</td>\n",
              "      <td>0.005243</td>\n",
              "      <td>0.021748</td>\n",
              "      <td>0.016893</td>\n",
              "      <td>0.063301</td>\n",
              "      <td>0.080583</td>\n",
              "      <td>0.020971</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.011456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ADP</th>\n",
              "      <td>0.038739</td>\n",
              "      <td>0.321053</td>\n",
              "      <td>0.008482</td>\n",
              "      <td>0.323585</td>\n",
              "      <td>0.014559</td>\n",
              "      <td>0.063299</td>\n",
              "      <td>0.000886</td>\n",
              "      <td>0.107102</td>\n",
              "      <td>0.016964</td>\n",
              "      <td>0.034561</td>\n",
              "      <td>0.069502</td>\n",
              "      <td>0.001266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <td>0.160900</td>\n",
              "      <td>0.056709</td>\n",
              "      <td>0.206459</td>\n",
              "      <td>0.061707</td>\n",
              "      <td>0.025759</td>\n",
              "      <td>0.003076</td>\n",
              "      <td>0.010381</td>\n",
              "      <td>0.017686</td>\n",
              "      <td>0.142253</td>\n",
              "      <td>0.075740</td>\n",
              "      <td>0.054210</td>\n",
              "      <td>0.185121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRON</th>\n",
              "      <td>0.041913</td>\n",
              "      <td>0.009567</td>\n",
              "      <td>0.484738</td>\n",
              "      <td>0.212756</td>\n",
              "      <td>0.036902</td>\n",
              "      <td>0.006834</td>\n",
              "      <td>0.005011</td>\n",
              "      <td>0.070615</td>\n",
              "      <td>0.022323</td>\n",
              "      <td>0.088383</td>\n",
              "      <td>0.006834</td>\n",
              "      <td>0.014123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRT</th>\n",
              "      <td>0.045010</td>\n",
              "      <td>0.101370</td>\n",
              "      <td>0.401174</td>\n",
              "      <td>0.250489</td>\n",
              "      <td>0.009393</td>\n",
              "      <td>0.056751</td>\n",
              "      <td>0.002348</td>\n",
              "      <td>0.082975</td>\n",
              "      <td>0.019569</td>\n",
              "      <td>0.012133</td>\n",
              "      <td>0.017613</td>\n",
              "      <td>0.001174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d849a75-5805-48f6-8ad9-ac217dd8fa52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d849a75-5805-48f6-8ad9-ac217dd8fa52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d849a75-5805-48f6-8ad9-ac217dd8fa52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing B\n",
        "B = np.empty((len(encode_hs), len(encode_vs)), dtype = np.float128)\n",
        "B[:,:] = 0\n",
        "for sentence in train_set:\n",
        "    for word, t in sentence:\n",
        "        B[encode_hs[t], encode_vs[word]] += 1\n",
        "\n",
        "B=B/np.reshape(np.sum(B, axis=1), (-1,1))\n",
        "print(pd.DataFrame(B, index = encode_hs.keys(), columns = encode_vs.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7TCjhmLRAZ2",
        "outputId": "aeb7bc33-2189-4749-af85-b5e725b290e2"
      },
      "id": "n7TCjhmLRAZ2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      negotiator     belts  galvanized   certain     Urban     ships  \\\n",
            ".       0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "DET     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "VERB    0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "NOUN    0.000044  0.000218    0.000000  0.000000  0.000044  0.000218   \n",
            "ADV     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "NUM     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "CONJ    0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "ADJ     0.000000  0.000000    0.000194  0.003301  0.000000  0.000000   \n",
            "ADP     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "X       0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "PRON    0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "PRT     0.000000  0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "      Services  intelligence  responses  short-term  ...  attached  reflect  \\\n",
            ".     0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "DET   0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "VERB  0.000000      0.000000   0.000000    0.000000  ...  0.000276  0.00046   \n",
            "NOUN  0.000131      0.000044   0.000131    0.000000  ...  0.000000  0.00000   \n",
            "ADV   0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "NUM   0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "CONJ  0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "ADJ   0.000000      0.000000   0.000000    0.002136  ...  0.000000  0.00000   \n",
            "ADP   0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "X     0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "PRON  0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "PRT   0.000000      0.000000   0.000000    0.000000  ...  0.000000  0.00000   \n",
            "\n",
            "       futures      soul  execution  bulldozers  sabotage  Leinonen    cancer  \\\n",
            ".     0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "DET   0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "VERB  0.000000  0.000000   0.000000    0.000000  0.000092  0.000000  0.000000   \n",
            "NOUN  0.002264  0.000044   0.000087    0.000044  0.000000  0.000087  0.000305   \n",
            "ADV   0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "NUM   0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "CONJ  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "ADJ   0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "ADP   0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "X     0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "PRON  0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "PRT   0.000000  0.000000   0.000000    0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "         grant  \n",
            ".     0.000000  \n",
            "DET   0.000000  \n",
            "VERB  0.000276  \n",
            "NOUN  0.000044  \n",
            "ADV   0.000000  \n",
            "NUM   0.000000  \n",
            "CONJ  0.000000  \n",
            "ADJ   0.000000  \n",
            "ADP   0.000000  \n",
            "X     0.000000  \n",
            "PRON  0.000000  \n",
            "PRT   0.000000  \n",
            "\n",
            "[12 rows x 11052 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba30571",
      "metadata": {
        "id": "0ba30571"
      },
      "outputs": [],
      "source": [
        "# compute Emission Probability\n",
        "def word_given_tag(word, tag, B=B, encode_hs=encode_hs, encode_vs=encode_vs):\n",
        "    # your code here\n",
        "    if word not in encode_vs.keys():\n",
        "        return 1\n",
        "    else:\n",
        "        # print(tag)\n",
        "        # print(encode_vs[word])\n",
        "        return B[encode_hs[tag], encode_vs[word]]\n",
        "\n",
        "\n",
        "\n",
        "# compute Transition Probability\n",
        "def t2_given_t1(t2, t1, train_bag = train_tagged_words, A=A, encode_hs=encode_hs):\n",
        "    # your code here\n",
        "    return A[t1,t2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a321eeee",
      "metadata": {
        "id": "a321eeee"
      },
      "outputs": [],
      "source": [
        "def Viterbi(words, train_bag = train_tagged_words, encode_hs = encode_hs, pi = pi):\n",
        "    # your code here\n",
        "\n",
        "    t = len(words) #Number of Time steps\n",
        "\n",
        "    #parents = np.zeros((t, len(encode_hs.keys())))\n",
        "    parents = np.zeros((len(encode_hs.keys()), t)) #My way\n",
        "    \n",
        "    #We'll use two layers\n",
        "    layer0 = pi.copy()\n",
        "    layer1 = np.zeros(len(pi))\n",
        "\n",
        "    #Setting up initial layer - time step 0\n",
        "    for tag in encode_hs.keys():\n",
        "        layer0[encode_hs[tag]] = layer0[encode_hs[tag]] * word_given_tag(words[0], tag)\n",
        "\n",
        "    #Working on time steps 1 to t\n",
        "    for i in range(1, t):\n",
        "        word = words[i]\n",
        "        #Working on each element\n",
        "        for j in range(len(encode_hs.keys())):\n",
        "            #Declaring a temporary variable\n",
        "            x = np.zeros(len(encode_hs.keys()))\n",
        "            #Calculating all possible combinations to jth hidden state\n",
        "            for k in range(len(encode_hs.keys())):\n",
        "                x[k] = layer0[k]*t2_given_t1(k,j) * word_given_tag(word, list(encode_hs.keys())[j])\n",
        "            \n",
        "            layer1[j] = x.max()\n",
        "\n",
        "            parents[j, i] = x.argmax()\n",
        "\n",
        "        \n",
        "        layer0=layer1.copy()\n",
        "\n",
        "\n",
        "    #Backtracking\n",
        "    sequence = [layer0.argmax()]\n",
        "    for i in range(1, t):\n",
        "        sequence+=[int(parents[sequence[-1], -i])]\n",
        "    \n",
        "    sequence = sequence[::-1]\n",
        "    return [decode_hs[state] for state in sequence]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1234)      # define a random seed to get same sentences when run multiple times\n",
        "\n",
        "# choose random 10 numbers\n",
        "rndom = [random.randint(1, len(test_set)) for x in range(10)]\n",
        "# list of 10 sentences on which to test the model\n",
        "test_run = [test_set[i] for i in rndom]\n",
        "\n",
        "# testing 10 sentences to check the accuracy\n",
        "t_seq = [] #sequence of all tags in each sentence - sentence wise\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for sentence in test_run:\n",
        "    s=[tup[0] for tup in sentence]\n",
        "    sequence = Viterbi(s)\n",
        "    t_seq.append(sequence)\n",
        "end = time.time()\n",
        "difference = end - start\n",
        " \n",
        "print(\"Time taken in seconds:\", difference)\n",
        "\n",
        "# list of tagged words\n",
        "test_run_base = [tup for sent in test_run for tup in sent]\n",
        "\n",
        "tagged_seq = []\n",
        "\n",
        "for l in t_seq:\n",
        "    tagged_seq += l\n",
        "\n",
        "# accuracy should be good enough (> 90%) to be a satisfactory model\n",
        "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j[1]] \n",
        " \n",
        "accuracy = len(check) / len(tagged_seq)\n",
        "print('Viterbi Algorithm Accuracy:', accuracy * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhqScpB5evhc",
        "outputId": "47f0d8ec-2869-4483-9e32-9b68e47afd18"
      },
      "id": "PhqScpB5evhc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken in seconds: 0.14170169830322266\n",
            "Viterbi Algorithm Accuracy: 93.30143540669856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toy Model"
      ],
      "metadata": {
        "id": "pu6ccRdbYYzM"
      },
      "id": "pu6ccRdbYYzM"
    },
    {
      "cell_type": "code",
      "source": [
        "#Going from Row to Column\n",
        "A = np.array([\n",
        "    #C,  H\n",
        "    [0.5,0.5],#C\n",
        "    [0.4,0.6]#H\n",
        "])\n",
        "\n",
        "B = np.array([\n",
        "    # 1,  2,  3\n",
        "    [0.5,0.4,0.1],#C\n",
        "    [0.2,0.4,0.4]#H\n",
        "])"
      ],
      "metadata": {
        "id": "rNB2VzBlwf-0"
      },
      "execution_count": null,
      "outputs": [],
      "id": "rNB2VzBlwf-0"
    },
    {
      "cell_type": "code",
      "source": [
        "#C,H\n",
        "pi = np.array([0.2,0.8])"
      ],
      "metadata": {
        "id": "2qqhrSkXwujT"
      },
      "execution_count": null,
      "outputs": [],
      "id": "2qqhrSkXwujT"
    },
    {
      "cell_type": "code",
      "source": [
        "#             3, 1, 3\n",
        "V = np.array([2,0,2])"
      ],
      "metadata": {
        "id": "yrzSVDaGw8Bp"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yrzSVDaGw8Bp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brute Force"
      ],
      "metadata": {
        "id": "ysqfGidVcofW"
      },
      "id": "ysqfGidVcofW"
    },
    {
      "cell_type": "code",
      "source": [
        "#['CHH', 'CHC', 'CCH', 'CCC', 'HHH', 'HHC', 'HCH', 'HCC']\n",
        "sequences = ['011', '010', '001', '000', '111', '110', '101', '100']"
      ],
      "metadata": {
        "id": "TpcP3Oo9m2ky"
      },
      "execution_count": null,
      "outputs": [],
      "id": "TpcP3Oo9m2ky"
    },
    {
      "cell_type": "code",
      "source": [
        "v1=2\n",
        "v2=0\n",
        "v3=2"
      ],
      "metadata": {
        "id": "E9T7VscjpbdY"
      },
      "execution_count": null,
      "outputs": [],
      "id": "E9T7VscjpbdY"
    },
    {
      "cell_type": "code",
      "source": [
        "d = {}\n",
        "for k in sequences:\n",
        "    s1=int(k[0])\n",
        "    s2=int(k[1])\n",
        "    s3=int(k[2])\n",
        "    d[k]=pi[s1] * A[s1,s2] * A[s2,s3]*B[s1,v1] * B[s2,v2] * B[s3,v3]\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTe_xYqEqc50",
        "outputId": "48dbe898-a539-4d89-d74f-dd8fa82376f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'011': 0.00048000000000000007, '010': 8.000000000000003e-05, '001': 0.0010000000000000002, '000': 0.00025000000000000006, '111': 0.009216, '110': 0.0015360000000000003, '101': 0.012800000000000004, '100': 0.003200000000000001}\n"
          ]
        }
      ],
      "id": "dTe_xYqEqc50"
    },
    {
      "cell_type": "code",
      "source": [
        "#Probability of this observation\n",
        "sum(d.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY9P4rlzqmxl",
        "outputId": "666ee4be-0637-473e-f091-5eb9aff62780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.028562000000000008"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "id": "dY9P4rlzqmxl"
    },
    {
      "cell_type": "code",
      "source": [
        "#Most Probable Hidden State Sequence\n",
        "m = max(d.values())\n",
        "for key, value in d.items():\n",
        "    if value == m:\n",
        "        print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhjrjn5yqok1",
        "outputId": "0d9dddd6-9419-4dbe-b1dc-b034d2d7c202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101\n"
          ]
        }
      ],
      "id": "Hhjrjn5yqok1"
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_toy(A, B, V):\n",
        "    #Initializing Arrays\n",
        "    t = len(V)\n",
        "    parents = np.empty((A.shape[0], t))\n",
        "    parents[:] = np.nan\n",
        "    values = np.empty((A.shape[0], t))\n",
        "    values[:] = np.nan\n",
        "\n",
        "    hs = list(range(A.shape[0]))\n",
        "    #Time step 1 - parents array doesn't need to be updated\n",
        "    for j in hs:\n",
        "        values[j,0] = pi[j] * B[j, V[0]]\n",
        "    \n",
        "    \n",
        "    #Time step 2 to t - parents array needs to be updated\n",
        "    for i in range(1,t):\n",
        "        for j in hs:\n",
        "            l = [values[k,i-1] * A[k,j] * B[j,V[i]] for k in hs]\n",
        "            #Values[k, i-1] signifies the previous step node.\n",
        "            #What this is doing is essentially calculating the probability of getting to the state j in time step i\n",
        "            #from all the hidden nodes at time step i-1\n",
        "            #and then outputting the given visible sequence node\n",
        "            #We store the maximum of it\n",
        "            values[j,i] = max(l)\n",
        "            parents[j,i] = np.argmax(l)\n",
        "    print(\"Parents: \\n\", parents)\n",
        "    print(\"Values: \\n\", values)\n",
        "    #Backtracking\n",
        "    sequence = \"\"\n",
        "    #Initial Step\n",
        "    sequence += str(np.argmax(values[:,-1]))\n",
        "    m = np.max(values[:,-1])\n",
        "    #Appending other steps\n",
        "    for i in range(1,t):\n",
        "        sequence+=str(int(parents[int(sequence[-1]), -i]))\n",
        "    \n",
        "    sequence = sequence[::-1]\n",
        "\n",
        "    return sequence, m\n",
        "viterbi_toy(A,B,V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96eatcFsMQj-",
        "outputId": "ee8f9eaa-ec39-4831-c958-bea3478e9a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parents: \n",
            " [[nan  1.  0.]\n",
            " [nan  1.  0.]]\n",
            "Values: \n",
            " [[0.02   0.064  0.0032]\n",
            " [0.32   0.0384 0.0128]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('101', 0.012800000000000004)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "id": "96eatcFsMQj-"
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(A, B, V):\n",
        "    #Initializing Arrays\n",
        "    t = len(V)\n",
        "    values = np.empty((A.shape[0], t))\n",
        "    values[:] = np.nan\n",
        "\n",
        "    hs = list(range(A.shape[0]))\n",
        "    #Time step 1 - initial probabilities\n",
        "    for j in hs:\n",
        "        values[j,0] = pi[j] * B[j, V[0]]\n",
        "    \n",
        "    \n",
        "    #Time step 2 to t\n",
        "    for i in range(1,t):\n",
        "        for j in hs:\n",
        "            l = [values[k,i-1] * A[k,j] * B[j,V[i]] for k in hs]\n",
        "            #Values[k, i-1] signifies the previous step node.\n",
        "            #What this is doing is essentially calculating the probability of getting to the state j in time step i\n",
        "            #from all the hidden nodes at time step i-1\n",
        "            #and then outputting the given visible sequence node\n",
        "            #We store the maximum of it\n",
        "            values[j,i] = sum(l)\n",
        "\n",
        "    return sum(values[:,-1])\n",
        "forward(A,B,V)"
      ],
      "metadata": {
        "id": "Eq9y20gQO_vF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f7f2b6-6c3b-40e9-9a07-e898bea3f9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02856200000000001"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "id": "Eq9y20gQO_vF"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pn9O9dbpc-t8"
      },
      "id": "pn9O9dbpc-t8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}